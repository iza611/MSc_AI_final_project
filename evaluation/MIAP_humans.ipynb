{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c89db38-dea8-44ea-b569-cf4569a7e0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIAP_YAML_PATH = f'./../training/data/MIAP.yaml'\n",
    "WEIGHTS_PATH = f'./../training/runs/train/MIAP_person_detection/weights/best.pt'\n",
    "MIAP_VAL_IMGS_PATH = f\"./../datasets/quali_tests/person_detection/converted\"\n",
    "NAME = 'MIAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d50722-964e-4079-b117-90f5680e56b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ 9e11c73 torch 2.3.0+cu121 CUDA:0 (NVIDIA A40, 45618.6875MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['./../training/runs/train/MIAP_person_detection/weights/best.pt'], data='./../training/data/MIAP.yaml', batch_size=64, img_size=640, conf_thres=0.001, iou_thres=0.65, task='val', device='0', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='MIAP', exist_ok=False, no_trace=False, v5_metric=True)\n",
      "Fusing layers... \n",
      "IDetect.fuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/yolo/lib/python3.10/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 208 layers, 6007596 parameters, 0 gradients, 13.0 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/yolo/lib/python3.10/site-packages/torch/nn/modules/module.py:1541: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return forward_call(*args, **kwargs)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/MIAP/labels/val.cache' images and labels... 7410 found, 0 missing, 0 empty, 85 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7410/7410 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with YOLOv5 AP metric...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [01:46<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        7325       23679       0.616       0.587       0.567       0.387\n",
      "Speed: 2.1/2.5/4.6 ms inference/NMS/total per 640x640 image at batch-size 64\n",
      "Results saved to runs/test/MIAP\n"
     ]
    }
   ],
   "source": [
    "%run ./../training/model/yolov7/test.py --data $MIAP_YAML_PATH --img 640 --batch 64 \\\n",
    "--device 0 --weights $WEIGHTS_PATH --name $NAME --v5-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b4c023-b2f6-439f-921c-05e03af2c660",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ 9e11c73 torch 2.3.0+cu121 CUDA:0 (NVIDIA A40, 45618.6875MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights=['./../training/runs/train/MIAP_person_detection/weights/best.pt'], source='./../datasets/quali_tests/person_detection/converted', img_size=640, conf_thres=0.317, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 208 layers, 6007596 parameters, 0 gradients, 13.0 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "IDetect.fuse\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/yolo/lib/python3.10/site-packages/torch/nn/modules/module.py:1541: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. (4.1ms) Inference, (0.4ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img1.jpg\n",
      "1 person, Done. (3.9ms) Inference, (1.4ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img10.jpg\n",
      "1 person, Done. (3.9ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img11.jpg\n",
      "10 persons, Done. (4.8ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img12.jpg\n",
      "2 persons, Done. (3.8ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img13.jpg\n",
      "4 persons, Done. (3.9ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img14.jpg\n",
      "2 persons, Done. (5.5ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img15.jpg\n",
      "4 persons, Done. (3.8ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img16.jpg\n",
      "Done. (4.0ms) Inference, (0.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img17.jpg\n",
      "5 persons, Done. (5.3ms) Inference, (1.4ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img18.jpg\n",
      "1 person, Done. (4.6ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img19.jpg\n",
      "5 persons, Done. (3.9ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img2.jpg\n",
      "3 persons, Done. (3.9ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img20.jpg\n",
      "10 persons, Done. (4.0ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img21.jpg\n",
      "7 persons, Done. (4.1ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img22.jpg\n",
      "4 persons, Done. (5.8ms) Inference, (1.6ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img23.jpg\n",
      "1 person, Done. (3.9ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img24.jpg\n",
      "2 persons, Done. (4.0ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img25.jpg\n",
      "1 person, Done. (4.6ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img26.jpg\n",
      "11 persons, Done. (3.9ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img27.jpg\n",
      "1 person, Done. (7.1ms) Inference, (1.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img28.jpg\n",
      "10 persons, Done. (4.8ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img29.jpg\n",
      "4 persons, Done. (5.8ms) Inference, (1.6ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img3.jpg\n",
      "2 persons, Done. (4.7ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img30.jpg\n",
      "Done. (4.7ms) Inference, (0.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img31.jpg\n",
      "1 person, Done. (4.7ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img32.jpg\n",
      "11 persons, Done. (4.9ms) Inference, (1.6ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img33.jpg\n",
      "8 persons, Done. (4.6ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img34.jpg\n",
      "2 persons, Done. (5.4ms) Inference, (1.6ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img35.jpg\n",
      "1 person, Done. (4.5ms) Inference, (1.4ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img36.jpg\n",
      "5 persons, Done. (6.5ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img37.jpg\n",
      "2 persons, Done. (6.9ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img38.jpg\n",
      "2 persons, Done. (8.3ms) Inference, (1.9ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img39.jpg\n",
      "2 persons, Done. (7.8ms) Inference, (1.7ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img4.jpg\n",
      "5 persons, Done. (4.7ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img40.jpg\n",
      "6 persons, Done. (5.0ms) Inference, (1.8ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img41.jpg\n",
      "1 person, Done. (4.6ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img42.jpg\n",
      "Done. (4.2ms) Inference, (0.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img43.jpg\n",
      "Done. (5.6ms) Inference, (0.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img44.jpg\n",
      "6 persons, Done. (3.9ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img45.jpg\n",
      "4 persons, Done. (4.1ms) Inference, (1.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img46.jpg\n",
      "5 persons, Done. (4.5ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img5.jpg\n",
      "5 persons, Done. (5.0ms) Inference, (1.3ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img6.jpg\n",
      "7 persons, Done. (4.5ms) Inference, (1.5ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img7.jpg\n",
      "1 person, Done. (3.9ms) Inference, (1.1ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img8.jpg\n",
      "2 persons, Done. (3.9ms) Inference, (1.2ms) NMS\n",
      " The image with the result is saved in: runs/detect/exp/img9.jpg\n",
      "Done. (5.038s)\n",
      "4.790855490643045ms Average Inference, 1.2626803439596426ms Average NMS\n"
     ]
    }
   ],
   "source": [
    "%run ./../training/model/yolov7/detect.py --weights $WEIGHTS_PATH --conf-thres 0.317 \\\n",
    "--img-size 640 --source $MIAP_VAL_IMGS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33017e36-35cf-4d6d-97a3-2c258b02d81b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolo)",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
