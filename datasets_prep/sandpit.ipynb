{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6db490f6-4e9f-40e4-9f3f-579fa00c6542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "# import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "import sys\n",
    "from os.path import abspath\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the new path to the system path\n",
    "base_path = abspath('./../training/model/yolov7/')\n",
    "sys.path.append(base_path)\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadImages\n",
    "from utils.general import check_img_size, non_max_suppression, scale_coords\n",
    "from utils.torch_utils import select_device, TracedModel\n",
    "\n",
    "\n",
    "def detect(opt):\n",
    "    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace\n",
    "\n",
    "    # Initialize\n",
    "    device = select_device(opt.device)\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    stride = int(model.stride.max())  # model stride\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "\n",
    "    if trace:\n",
    "        model = TracedModel(model, device, opt.img_size)\n",
    "\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Set Dataloader\n",
    "    dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
    "\n",
    "    # Get names and colors\n",
    "    # names = model.module.names if hasattr(model, 'module') else model.names\n",
    "\n",
    "    # Run inference\n",
    "    if device.type != 'cpu':\n",
    "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "    old_img_w = old_img_h = imgsz\n",
    "    old_img_b = 1\n",
    "\n",
    "    for path, img, im0s, vid_cap in tqdm(dataset):\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Warmup\n",
    "        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
    "            old_img_b = img.shape[0]\n",
    "            old_img_h = img.shape[2]\n",
    "            old_img_w = img.shape[3]\n",
    "            for i in range(3):\n",
    "                model(img, augment=opt.augment)[0]\n",
    "\n",
    "        # Inference\n",
    "        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n",
    "            pred = model(img, augment=opt.augment)[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
    "\n",
    "            p = Path(p)  # to Path        p.name=img.jpg\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} person{'s' * (n > 1)}, \"  # add to string\n",
    "                    print(s)\n",
    "                \n",
    "                print(det)\n",
    "                # for *xyxy, conf, cls in reversed(det):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c754d68-d7be-40ff-9fb0-31cdc81723eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ 690594c torch 2.3.0+cu121 CUDA:0 (NVIDIA A40, 45618.6875MB)\n",
      "\n",
      "Model Summary: 208 layers, 6007596 parameters, 0 gradients, 13.0 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "IDetect.fuse\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[2.36000e+02, 5.79000e+02, 1.10600e+03, 1.91800e+03, 7.39746e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 2/100 [00:00<00:07, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[2.82000e+02, 4.44000e+02, 1.43000e+03, 1.91700e+03, 8.94531e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.41000e+02, 4.54000e+02, 1.09000e+03, 1.91700e+03, 8.91602e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 4/100 [00:00<00:07, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 persons, \n",
      "tensor([[6.46000e+02, 3.07000e+02, 1.26900e+03, 9.79000e+02, 8.11523e-01, 0.00000e+00],\n",
      "        [1.58800e+03, 5.12000e+02, 1.66000e+03, 6.08000e+02, 3.64746e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 6/100 [00:00<00:07, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 persons, \n",
      "tensor([[5.82000e+02, 5.38000e+02, 7.90000e+02, 1.15100e+03, 9.02832e-01, 0.00000e+00],\n",
      "        [0.00000e+00, 1.06400e+03, 4.63000e+02, 1.92000e+03, 5.41992e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.60000e+02, 3.53000e+02, 8.25000e+02, 1.91400e+03, 9.07715e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.00000e+01, 1.70000e+02, 8.89000e+02, 7.20000e+02, 6.51367e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 8/100 [00:00<00:07, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[3.21000e+02, 7.48000e+02, 1.35200e+03, 1.91700e+03, 8.57910e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.30000e+01, 6.28000e+02, 1.02800e+03, 1.91700e+03, 8.41797e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 10/100 [00:00<00:06, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[3.00000e+01, 1.05300e+03, 1.33500e+03, 1.91800e+03, 7.78809e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 12/100 [00:00<00:06, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[1.90000e+01, 4.41000e+02, 1.40100e+03, 1.91700e+03, 8.59375e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.70000e+01, 2.02000e+02, 1.33400e+03, 1.90800e+03, 6.66016e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[1.83000e+02, 3.54000e+02, 3.44000e+02, 5.64000e+02, 8.23242e-01, 0.00000e+00],\n",
      "        [2.31000e+02, 4.60000e+01, 1.08000e+03, 7.14000e+02, 7.35840e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 14/100 [00:01<00:05, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[3.35000e+02, 1.19000e+02, 1.07500e+03, 1.92000e+03, 8.95508e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 16/100 [00:01<00:06, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[7.76000e+02, 6.86000e+02, 1.21000e+03, 1.43900e+03, 8.65234e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.93000e+02, 4.00000e+02, 9.65000e+02, 1.66200e+03, 8.16895e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.60000e+01, 6.63000e+02, 1.42800e+03, 1.90200e+03, 8.00293e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 18/100 [00:01<00:06, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 persons, \n",
      "tensor([[2.24000e+02, 1.26600e+03, 1.03000e+03, 1.92000e+03, 8.19336e-01, 0.00000e+00],\n",
      "        [9.88000e+02, 2.30000e+01, 1.44000e+03, 1.90800e+03, 5.41504e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.44000e+02, 4.46000e+02, 1.47800e+03, 1.43800e+03, 8.53027e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 20/100 [00:01<00:06, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[4.92000e+02, 6.08000e+02, 1.17400e+03, 1.83300e+03, 8.86719e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 22/100 [00:01<00:06, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[4.40000e+02, 1.23400e+03, 1.03800e+03, 1.91800e+03, 8.78906e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[4.47000e+02, 3.44000e+02, 1.10600e+03, 1.90500e+03, 8.84766e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.17000e+02, 5.30000e+02, 1.42000e+03, 1.91600e+03, 8.23730e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 24/100 [00:01<00:05, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[3.50000e+02, 8.19000e+02, 9.50000e+02, 1.91700e+03, 8.70605e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.96000e+02, 7.48000e+02, 1.03900e+03, 1.87000e+03, 7.52930e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–Œ       | 26/100 [00:02<00:06, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[3.12000e+02, 9.02000e+02, 1.27200e+03, 1.92000e+03, 8.33496e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 28/100 [00:02<00:05, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[2.09000e+02, 1.22000e+02, 1.26700e+03, 1.02000e+03, 7.18262e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.83000e+02, 6.18000e+02, 1.16700e+03, 1.91700e+03, 8.45703e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.10000e+01, 5.99000e+02, 1.25000e+03, 1.92000e+03, 5.87891e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:02<00:04, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[1.60000e+01, 1.40000e+01, 1.43200e+03, 1.91600e+03, 9.24316e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.50000e+01, 1.20000e+01, 1.31600e+03, 1.91700e+03, 9.24805e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[ 11.00000,  57.00000, 585.00000, 479.00000,   0.76465,   0.00000]], device='cuda:0')\n",
      "1 person, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:02<00:04, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.66000e+02, 5.64000e+02, 1.19600e+03, 1.91600e+03, 8.16895e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[118.00000,  20.00000, 500.00000, 479.00000,   0.68066,   0.00000]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[5.32000e+02, 1.19200e+03, 1.07400e+03, 1.92000e+03, 8.03711e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[1.20000e+01, 3.68000e+02, 1.28000e+02, 5.17000e+02, 8.13965e-01, 0.00000e+00],\n",
      "        [2.85000e+02, 2.94000e+02, 1.18900e+03, 7.20000e+02, 7.44629e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:02<00:04, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[1.91000e+02, 6.18000e+02, 8.96000e+02, 1.92000e+03, 7.54395e-01, 0.00000e+00]], device='cuda:0')\n",
      "3 persons, \n",
      "tensor([[1.68000e+02, 2.05000e+02, 3.15000e+02, 4.79000e+02, 6.30859e-01, 0.00000e+00],\n",
      "        [2.36000e+02, 2.90000e+02, 4.00000e+02, 4.80000e+02, 6.25000e-01, 0.00000e+00],\n",
      "        [3.98000e+02, 1.00000e+00, 6.40000e+02, 4.78000e+02, 5.55176e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[5.13000e+02, 3.87000e+02, 9.10000e+02, 1.72800e+03, 7.88086e-01, 0.00000e+00],\n",
      "        [1.22200e+03, 1.57600e+03, 1.44000e+03, 1.92000e+03, 5.68359e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.43000e+02, 7.30000e+02, 8.46000e+02, 1.88800e+03, 8.92090e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [00:03<00:03, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[4.46000e+02, 9.80000e+01, 1.09400e+03, 1.91000e+03, 8.83789e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[2.20000e+02, 6.08000e+02, 1.43400e+03, 1.92000e+03, 7.60254e-01, 0.00000e+00],\n",
      "        [1.10100e+03, 1.26000e+02, 1.30500e+03, 3.15000e+02, 3.85742e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[4.50000e+02, 1.27000e+02, 6.94000e+02, 8.82000e+02, 8.35449e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.27000e+02, 6.19000e+02, 7.82000e+02, 1.92000e+03, 8.67676e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:03<00:03, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 persons, \n",
      "tensor([[2.46000e+02, 4.60000e+01, 7.79000e+02, 1.30300e+03, 8.64258e-01, 0.00000e+00],\n",
      "        [2.42000e+02, 1.59900e+03, 4.10000e+02, 1.92000e+03, 4.05518e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[7.12000e+02, 2.81000e+02, 1.45400e+03, 1.08400e+03, 8.53516e-01, 0.00000e+00],\n",
      "        [0.00000e+00, 5.64000e+02, 2.59000e+02, 7.92000e+02, 5.25879e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[8.00000e+00, 1.00000e+01, 1.43600e+03, 1.91400e+03, 9.34082e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [00:03<00:03, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[1.56000e+02, 5.40000e+02, 1.43700e+03, 1.91400e+03, 7.88574e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[5.21000e+02, 9.40000e+01, 1.40800e+03, 1.07200e+03, 8.55957e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.30000e+02, 6.30000e+02, 1.15800e+03, 1.91800e+03, 8.33008e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:03<00:03, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[3.30000e+01, 2.39000e+02, 1.43500e+03, 1.91700e+03, 9.01367e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.52000e+02, 7.96000e+02, 1.23900e+03, 1.91800e+03, 6.09375e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[4.93000e+02, 2.78000e+02, 1.21200e+03, 1.20000e+03, 7.75879e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [00:04<00:03, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[4.22000e+02, 2.66000e+02, 1.38200e+03, 1.91400e+03, 8.16895e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.60000e+01, 4.49000e+02, 1.43300e+03, 1.91700e+03, 6.63086e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.83000e+02, 7.13000e+02, 1.23600e+03, 1.92000e+03, 8.54492e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:04<00:03, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[2.82000e+02, 2.23000e+02, 1.24800e+03, 1.63800e+03, 4.90234e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[5.64000e+02, 1.64000e+02, 1.19200e+03, 1.06800e+03, 9.05762e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[0.00000e+00, 7.12000e+02, 9.22000e+02, 1.92000e+03, 4.84375e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [00:04<00:02, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[8.70000e+01, 2.82000e+02, 1.10100e+03, 1.91400e+03, 8.94531e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[6.80000e+02, 1.09000e+03, 8.68000e+02, 1.50900e+03, 7.52441e-01, 0.00000e+00],\n",
      "        [6.40000e+01, 4.61000e+02, 1.20400e+03, 1.91800e+03, 6.06445e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.38000e+02, 5.90000e+02, 1.44000e+03, 1.90200e+03, 7.47070e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[3.19000e+02, 1.18000e+02, 1.02700e+03, 7.18000e+02, 7.53418e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [00:04<00:02, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[5.59000e+02, 2.51000e+02, 1.28000e+03, 8.78000e+02, 8.56445e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.92000e+02, 3.65000e+02, 1.11400e+03, 1.91700e+03, 8.48633e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.02000e+02, 8.50000e+02, 8.80000e+02, 1.91800e+03, 8.60840e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:04<00:02, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[7.60000e+01, 2.08000e+02, 1.31200e+03, 1.88100e+03, 7.90527e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[4.68000e+02, 5.18000e+02, 8.69000e+02, 9.60000e+02, 8.57910e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.50000e+02, 7.58000e+02, 7.16000e+02, 1.91400e+03, 8.69629e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [00:05<00:01, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[4.41000e+02, 2.28000e+02, 1.04300e+03, 1.75500e+03, 8.81348e-01, 0.00000e+00]], device='cuda:0')\n",
      "3 persons, \n",
      "tensor([[1.32000e+02, 7.78000e+02, 1.14400e+03, 1.92000e+03, 7.21191e-01, 0.00000e+00],\n",
      "        [7.74000e+02, 1.00000e+02, 8.96000e+02, 2.21000e+02, 5.90820e-01, 0.00000e+00],\n",
      "        [9.01000e+02, 2.33000e+02, 9.79000e+02, 3.00000e+02, 4.56055e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.66000e+02, 4.28000e+02, 1.30200e+03, 1.91600e+03, 8.60352e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:05<00:01, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[6.33000e+02, 1.46000e+02, 1.72400e+03, 1.43800e+03, 6.90430e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[5.56000e+02, 1.44000e+02, 1.31000e+03, 8.80000e+02, 8.34961e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[0.00000e+00, 7.17000e+02, 1.40100e+03, 1.91800e+03, 8.50586e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[3.81000e+02, 1.87000e+02, 9.52000e+02, 7.17000e+02, 8.66699e-01, 0.00000e+00],\n",
      "        [1.80000e+01, 2.58000e+02, 1.06000e+02, 4.02000e+02, 4.71191e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:05<00:01, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[3.60000e+01, 6.00000e+00, 1.27400e+03, 7.20000e+02, 7.73926e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[9.70000e+01, 5.91000e+02, 6.89000e+02, 1.92000e+03, 8.95508e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[7.48000e+02, 5.66000e+02, 1.19300e+03, 1.42100e+03, 9.13574e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [00:05<00:00, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[2.52000e+02, 4.72000e+02, 9.14000e+02, 1.91400e+03, 8.93066e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.26000e+02, 1.21000e+02, 8.44000e+02, 7.13000e+02, 8.00293e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[4.21000e+02, 2.26000e+02, 1.07900e+03, 7.17000e+02, 8.35449e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.04000e+02, 6.74000e+02, 1.32900e+03, 1.87000e+03, 7.27051e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[4.85000e+02, 2.25000e+02, 1.62900e+03, 1.43600e+03, 6.99707e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:06<00:00, 17.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[6.22000e+02, 8.80000e+02, 1.18000e+03, 1.91700e+03, 8.91113e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[3.05000e+02, 3.68000e+02, 1.35000e+03, 1.43800e+03, 8.07129e-01, 0.00000e+00],\n",
      "        [1.52000e+03, 3.53000e+02, 1.75000e+03, 7.10000e+02, 6.29395e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.00000e+02, 4.20000e+02, 1.30000e+03, 1.91700e+03, 7.73438e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[5.34000e+02, 1.71000e+02, 1.41600e+03, 1.43200e+03, 8.56934e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:06<00:00, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[1.48000e+02, 2.02000e+02, 1.41000e+03, 1.90800e+03, 6.62598e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n",
      "tensor([[2.46000e+02, 1.24000e+02, 1.10100e+03, 1.91400e+03, 8.99902e-01, 0.00000e+00],\n",
      "        [1.05700e+03, 5.81000e+02, 1.30700e+03, 9.16000e+02, 8.30078e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[9.80000e+01, 6.85000e+02, 1.09700e+03, 1.92000e+03, 5.08789e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[  4.00000,   4.00000, 478.00000, 638.00000,   0.93164,   0.00000]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[4.05000e+02, 9.10000e+02, 9.79000e+02, 1.92000e+03, 8.99414e-01, 0.00000e+00]], device='cuda:0')\n",
      "2 persons, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [00:06<00:00, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.03000e+02, 1.04600e+03, 1.19400e+03, 1.92000e+03, 8.22754e-01, 0.00000e+00],\n",
      "        [1.02000e+02, 9.62000e+02, 1.56000e+02, 1.07200e+03, 4.33105e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[5.50000e+02, 6.16000e+02, 1.29600e+03, 1.44000e+03, 7.74902e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.00000e+01, 1.54000e+02, 1.82400e+03, 1.44000e+03, 4.67773e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.49000e+02, 6.73000e+02, 1.13700e+03, 1.92000e+03, 8.15430e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:06<00:00, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 person, \n",
      "tensor([[5.30000e+01, 2.70000e+02, 1.31600e+03, 1.91700e+03, 7.86133e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[2.06000e+02, 5.08000e+02, 1.10800e+03, 1.91700e+03, 8.87695e-01, 0.00000e+00]], device='cuda:0')\n",
      "1 person, \n",
      "tensor([[1.11000e+02, 8.38000e+02, 1.33200e+03, 1.92000e+03, 7.14844e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "opt = argparse.Namespace(\n",
    "    weights=['./../training/runs/train/MIAP_person_detection/weights/best.pt'],\n",
    "    source=\"./../datasets/HaGRID_test/like\",\n",
    "    img_size=640,\n",
    "    conf_thres=0.317,\n",
    "    iou_thres=0.45,\n",
    "    device='0',\n",
    "    view_img=False,\n",
    "    save_txt=False,\n",
    "    save_conf=False,\n",
    "    nosave=False,\n",
    "    classes=None,\n",
    "    agnostic_nms=False,\n",
    "    augment=False,\n",
    "    update=False,\n",
    "    project='runs/detect',\n",
    "    name='reducing_detect_func',\n",
    "    exist_ok=False,\n",
    "    no_trace=False\n",
    ")\n",
    "\n",
    "detect(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a96ab-d2cf-4faf-8902-709024fc35af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314452a-2d77-405e-a5d1-2485fc63f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.general import xyxy2xywh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolo)",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
