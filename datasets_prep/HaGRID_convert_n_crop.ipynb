{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "262c9e50-e0b5-491e-b886-d0446cb74bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gesture_type = 'two_up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3fcdf32-8d97-4afa-9d8a-4b4c41ef560a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Images\n",
      "30688\n",
      "30688\n",
      "Train Labels\n",
      "22688\n",
      "22688\n",
      "True\n",
      "Test Labels\n",
      "5000\n",
      "5000\n",
      "True\n",
      "Val Labels\n",
      "3000\n",
      "3000\n",
      "True\n",
      "Labels Combined\n",
      "30688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "img_SOURCE = f\"./../datasets/HaGRID/{gesture_type}/\"\n",
    "all_images_of_given_gesture = [f for f in os.listdir(os.path.join(img_SOURCE)) if f.endswith('.jpg')]\n",
    "all_images_of_given_gesture_set = set(os.path.splitext(f)[0] for f in all_images_of_given_gesture)\n",
    "\n",
    "print(\"All Images\")\n",
    "print(len(all_images_of_given_gesture))\n",
    "print(len(all_images_of_given_gesture_set))\n",
    "\n",
    "train_labels_SOURCE = f\"./../datasets/HaGRID/train/{gesture_type}.json\"\n",
    "test_labels_SOURCE = f\"./../datasets/HaGRID/test/{gesture_type}.json\"\n",
    "val_labels_SOURCE = f\"./../datasets/HaGRID/val/{gesture_type}.json\"\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "val_labels = []\n",
    "\n",
    "with open(train_labels_SOURCE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for image_id, info in data.items():\n",
    "        train_labels.append(image_id)\n",
    "        \n",
    "with open(test_labels_SOURCE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for image_id, info in data.items():\n",
    "        test_labels.append(image_id)\n",
    "        \n",
    "with open(val_labels_SOURCE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for image_id, info in data.items():\n",
    "        val_labels.append(image_id)\n",
    "\n",
    "print(\"Train Labels\")\n",
    "train_labels_set = set(train_labels)\n",
    "print(len(train_labels))\n",
    "print(len(train_labels_set))\n",
    "print(train_labels_set.issubset(all_images_of_given_gesture_set))\n",
    "\n",
    "print(\"Test Labels\")\n",
    "test_labels_set = set(test_labels)\n",
    "print(len(test_labels))\n",
    "print(len(test_labels_set))\n",
    "print(test_labels_set.issubset(all_images_of_given_gesture_set))\n",
    "\n",
    "print(\"Val Labels\")\n",
    "val_labels_set = set(val_labels)\n",
    "print(len(val_labels))\n",
    "print(len(val_labels_set))\n",
    "print(val_labels_set.issubset(all_images_of_given_gesture_set))\n",
    "\n",
    "print(\"Labels Combined\")\n",
    "labels_set = train_labels_set | test_labels_set | val_labels_set\n",
    "print(len(labels_set))\n",
    "labels_set == all_images_of_given_gesture_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90129ac2-2552-406f-8316-a44577466f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_type = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10014683-61cb-4197-b533-5a7a3dbdff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = \"./../training/runs/train/MIAP_person_detection/weights/best.pt\"\n",
    "SOURCE = f\"./../datasets/HaGRID/{set_type}/{gesture_type}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6287753-3107-4e3d-89ef-d4e1a403fad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils.torch_utils:YOLOR ðŸš€ 893edf6 torch 2.3.0+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81221.8125MB)\n",
      "\n",
      "INFO:utils.torch_utils:Model Summary: 208 layers, 6007596 parameters, 0 gradients, 13.0 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "IDetect.fuse\n",
      " Convert model to Traced-model... \n",
      " traced_script_module saved! \n",
      " model is traced! \n",
      "\n",
      "found 3000 image IDs in ./../datasets/HaGRID/val/two_up.json\n",
      "ended up with 3000 IDs after converting to a set\n",
      "list image path length = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [02:32, 19.61it/s]\n"
     ]
    }
   ],
   "source": [
    "%run ./HaGRID_conversion_utils/detect.py --weights $WEIGHTS --conf-thres 0.317 \\\n",
    "--device '0' --img-size 640 --source $SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de3e4a9c-5ddc-4b78-81b7-133fb49697f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All filenames match!\n",
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directories\n",
    "images_dir = f'./../datasets/HaGRID_converted/images/{set_type}'\n",
    "labels_dir = f'./../datasets/HaGRID_converted/labels/{set_type}'\n",
    "\n",
    "# Get the list of filenames (without extensions) in both directories\n",
    "image_filenames = {os.path.splitext(f)[0] for f in os.listdir(images_dir) if f.endswith('.jpg')}\n",
    "label_filenames = {os.path.splitext(f)[0] for f in os.listdir(labels_dir) if f.endswith('.txt')}\n",
    "\n",
    "# Find mismatches\n",
    "missing_in_labels = image_filenames - label_filenames\n",
    "missing_in_images = label_filenames - image_filenames\n",
    "\n",
    "# Print results\n",
    "if not missing_in_labels and not missing_in_images:\n",
    "    print(\"All filenames match!\")\n",
    "else:\n",
    "    if missing_in_labels:\n",
    "        print(\"Images without labels:\", missing_in_labels)\n",
    "    if missing_in_images:\n",
    "        print(\"Labels without images:\", missing_in_images)\n",
    "\n",
    "print(len(image_filenames))\n",
    "set(image_filenames) == set(label_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67bf25d0-e345-4724-adf0-f3f309a18e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HaGRID_converted dataset is located in /home/jovyan/datasets/HaGRID_converted. Directory content:\n",
      "\n",
      "images\n",
      "â”œâ”€â”€test    <-- contains 20000 files\n",
      "â”œâ”€â”€train    <-- contains 92795 files\n",
      "â”œâ”€â”€val    <-- contains 12000 files\n",
      "labels\n",
      "â”œâ”€â”€test    <-- contains 20000 files\n",
      "â”œâ”€â”€train    <-- contains 92795 files\n",
      "â”œâ”€â”€val    <-- contains 12000 files\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import abspath, join, isdir, isfile\n",
    "\n",
    "path = f\"./../datasets/HaGRID_converted/\"\n",
    "print(\"The HaGRID_converted dataset is located in \" + abspath(path) + \". Directory content:\\n\")\n",
    "\n",
    "content = sorted(listdir(path))\n",
    "directories = [directory for directory in content if isdir(join(path, directory))]\n",
    "\n",
    "for directory in directories:\n",
    "    if not directory.startswith('.'):\n",
    "        print(directory)\n",
    "        subcontent = sorted(listdir(join(path, directory)))\n",
    "        for file in subcontent:\n",
    "            subdirectory_path = join(path, directory, file)\n",
    "            if isdir(subdirectory_path):\n",
    "                num_files = len([f for f in listdir(subdirectory_path) if isfile(join(subdirectory_path, f))])\n",
    "                print('â”œâ”€â”€' + file + f\"    <-- contains {num_files} files\") if not file.startswith('.') else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
