{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e947ae-0fc6-47c3-a48c-507528f1e55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIAP_yaml_path = './data/MIAP.yaml'\n",
    "YOLOv7tiny_yaml_path = './model/yolov7-tiny.yaml'\n",
    "YOLOv7tiny_weights_path = './model/yolov7-tiny.pt'\n",
    "YOLOv7tiny_hyp_path = './model/yolov7/data/hyp.scratch.tiny.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03295d-015f-4396-869c-093826c26a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.3.0+cu121 CUDA:0 (NVIDIA A40, 45618.6875MB)\n",
      "\n",
      "Namespace(weights='./model/yolov7-tiny.pt', cfg='./model/yolov7-tiny.yaml', data='./data/MIAP.yaml', hyp='./model/yolov7/data/hyp.scratch.tiny.yaml', epochs=100, batch_size=32, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=4, project='runs/train', entity=None, name='MIAP_person_detection', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/MIAP_person_detection2', total_batch_size=32)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.05, copy_paste=0.0, paste_in=0.05, loss_ota=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device argument received: 0\n",
      "Device selected: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miza611\u001b[0m (\u001b[33mqmul-msc-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/training/wandb/run-20240605_164948-ectszocy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/qmul-msc-ai/YOLOR/runs/ectszocy' target=\"_blank\">MIAP_person_detection2</a></strong> to <a href='https://wandb.ai/qmul-msc-ai/YOLOR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/qmul-msc-ai/YOLOR' target=\"_blank\">https://wandb.ai/qmul-msc-ai/YOLOR</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/qmul-msc-ai/YOLOR/runs/ectszocy' target=\"_blank\">https://wandb.ai/qmul-msc-ai/YOLOR/runs/ectszocy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
      "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
      "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1     34156  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "/home/jovyan/yolo/lib/python3.10/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 415 layers, 37196556 parameters, 37196556 gradients, 105.1 GFLOPS\n",
      "\n",
      "Transferred 102/566 items from ./model/yolov7-tiny.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../datasets/MIAP/labels/train.cache' images and labels... 70000 found, 0 missing, 0 empty, 35 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70000/70000 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../datasets/MIAP/labels/val.cache' images and labels... 7410 found, 0 missing, 0 empty, 85 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7410/7410 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.64, Best Possible Recall (BPR) = 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image sizes 640 train, 640 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/MIAP_person_detection2\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 on device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      0/99      2.7G   0.06133   0.03659         0   0.09792        81       640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2187/2187 [55:22<00:00,  1.52s/it] \n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [02:15<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all        7325       23679       0.304       0.324       0.221      0.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 on device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/99     23.3G   0.04795   0.03421         0   0.08216       423       640:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1213/2187 [29:48<26:40,  1.64s/it] "
     ]
    }
   ],
   "source": [
    "%run ./model/yolov7/train.py --epochs 100 --workers 4 --device 0 --batch-size 32 \\\n",
    "--data $MIAP_yaml_path --img 640 640 --cfg $YOLOv7tiny_yaml_path \\\n",
    "--weights $YOLOv7tiny_weights_path --name MIAP_person_detection --hyp $YOLOv7tiny_hyp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5c8a7-97ba-4808-84e8-3e5294a43c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ./model/yolov7/train.py --resume True --epochs 100 --workers 4 --device 0 --batch-size 32 \\\n",
    "--data $MIAP_yaml_path --img 640 640 --cfg $YOLOv7tiny_yaml_path \\\n",
    "--weights $YOLOv7tiny_weights_path --name MIAP_person_detection --hyp $YOLOv7tiny_hyp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08ec45-3e6f-48e1-9c0b-18e949f946e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yolo)",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
