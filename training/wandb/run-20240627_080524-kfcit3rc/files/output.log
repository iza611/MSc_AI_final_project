                 from  n    params  module                                  arguments
  0                -1  1       928  models.common.Conv                      [3, 32, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
  2                -1  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  3                -2  1      2112  models.common.Conv                      [64, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  4                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  5                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  6  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
  7                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
  8                -1  1         0  models.common.MP                        []
  9                -1  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 10                -2  1      4224  models.common.Conv                      [64, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 12                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 13  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 15                -1  1         0  models.common.MP                        []
 16                -1  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 17                -2  1     16640  models.common.Conv                      [128, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 20  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 22                -1  1         0  models.common.MP                        []
 23                -1  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 24                -2  1     66048  models.common.Conv                      [256, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 27  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 29                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 30                -2  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 31                -1  1         0  models.common.SP                        [5]
 32                -2  1         0  models.common.SP                        [9]
 33                -3  1         0  models.common.SP                        [13]
 34  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 35                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 36          [-1, -7]  1         0  models.common.Concat                    [1]
 37                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 38                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 39                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 40                21  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 41          [-1, -2]  1         0  models.common.Concat                    [1]
 42                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 43                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 44                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 45                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 46  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 47                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 48                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 50                14  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 51          [-1, -2]  1         0  models.common.Concat                    [1]
 52                -1  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 53                -2  1      4160  models.common.Conv                      [128, 32, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 54                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 55                -1  1      9280  models.common.Conv                      [32, 32, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 56  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 57                -1  1      8320  models.common.Conv                      [128, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 58                -1  1     73984  models.common.Conv                      [64, 128, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
 59          [-1, 47]  1         0  models.common.Concat                    [1]
 60                -1  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 61                -2  1     16512  models.common.Conv                      [256, 64, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 62                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 63                -1  1     36992  models.common.Conv                      [64, 64, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 64  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 65                -1  1     33024  models.common.Conv                      [256, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 66                -1  1    295424  models.common.Conv                      [128, 256, 3, 2, None, 1, LeakyReLU(negative_slope=0.1)]
 67          [-1, 37]  1         0  models.common.Concat                    [1]
 68                -1  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 69                -2  1     65792  models.common.Conv                      [512, 128, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 70                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 71                -1  1    147712  models.common.Conv                      [128, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 72  [-1, -2, -3, -4]  1         0  models.common.Concat                    [1]
 73                -1  1    131584  models.common.Conv                      [512, 256, 1, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 74                57  1     73984  models.common.Conv                      [64, 128, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 75                65  1    295424  models.common.Conv                      [128, 256, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 76                73  1   1180672  models.common.Conv                      [256, 512, 3, 1, None, 1, LeakyReLU(negative_slope=0.1)]
 77      [74, 75, 76]  1     17132  models.yolo.IDetect                     [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
/home/jovyan/yolo/lib/python3.10/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 263 layers, 6014988 parameters, 6014988 gradients, 13.2 GFLOPS
Transferred 342/344 items from ./runs/train/MIAP_person_detection/weights/best.pt
Scaled weight_decay = 0.0005
Optimizer groups: 58 .bias, 58 conv.weight, 61 other
[34m[1mtrain: [39m[22mScanning '../datasets/SIGGI/targets/5/labels/train.cache' images and labels... 480 found, 0 missing, 240 empty, 0 corrupted: 100%|██████████| 480/480 [00:00<?, ?it/s]
Model moved to device: cuda:0
[34m[1mautoanchor: [39m[22mAnalyzing anchors... anchors/target = 4.52, Best Possible Recall (BPR) = 1.0000
Epoch 0/100 on device cuda:0
[34m[1mval: [39m[22mScanning '../datasets/SIGGI/targets/5/labels/val.cache' images and labels... 120 found, 0 missing, 60 empty, 0 corrupted: 100%|██████████| 120/120 [00:00<?, ?it/s]
Image sizes 640 train, 640 test
Using 4 dataloader workers
Logging results to runs/train/experiments/SIGGI_5_adam
Starting training for 100 epochs...
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size








      0/99     5.46G   0.02753  0.007314         0   0.03484        28       640: 100%|██████████| 15/15 [04:57<00:00, 19.86s/it]

               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
                 all         120          60       0.174       0.583       0.168       0.073
val_obj_loss=0.008647983893752098
patience_counter=0
Epoch 1/100 on device cuda:0
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size








      1/99     5.14G   0.02997  0.004872         0   0.03485        22       640: 100%|██████████| 15/15 [04:01<00:00, 16.08s/it]
               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  3.26it/s]
                 all         120          60       0.179       0.583       0.145      0.0578
val_obj_loss=0.010659035295248032
patience_counter=1
Epoch 2/100 on device cuda:0
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size
      2/99     6.03G   0.02878  0.005339         0   0.03412        40       640:  20%|██        | 3/15 [00:43<03:54, 19.52s/it]
      2/99     6.03G   0.03013  0.005024         0   0.03516        27       640:  27%|██▋       | 4/15 [01:05<03:46, 20.63s/it]
      2/99     6.03G   0.03157   0.00506         0   0.03663        36       640:  40%|████      | 6/15 [01:06<01:20,  8.91s/it]
      2/99     6.03G   0.03143  0.005164         0   0.03659        41       640:  47%|████▋     | 7/15 [01:37<02:10, 16.33s/it]
      2/99     6.03G   0.03053  0.005056         0   0.03559        32       640:  67%|██████▋   | 10/15 [02:04<00:46,  9.34s/it]
      2/99     6.03G   0.03046  0.005027         0   0.03548        27       640:  73%|███████▎  | 11/15 [02:29<00:57, 14.30s/it]
      2/99     6.03G   0.03044  0.004947         0   0.03539        40       640:  93%|█████████▎| 14/15 [03:03<00:09,  9.94s/it]
      2/99     6.03G   0.03035  0.004859         0   0.03521        24       640: 100%|██████████| 15/15 [03:24<00:00, 13.18s/it]
      2/99     6.03G   0.03035  0.004859         0   0.03521        24       640: 100%|██████████| 15/15 [03:24<00:00, 13.18s/it]
      2/99     6.03G   0.03035  0.004859         0   0.03521        24       640: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
      2/99     6.03G   0.03035  0.004859         0   0.03521        24       640: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
val_obj_loss=0.007266177795827389
patience_counter=0
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
                 all         120          60       0.452       0.817       0.593       0.362
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
val_obj_loss=0.00726817874237895
patience_counter=1
Epoch 4/100 on device cuda:0
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
     Epoch   gpu_mem       box       obj       cls     total    labels  img_size: 100%|██████████| 15/15 [03:24<00:00, 13.62s/it]
               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]
               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]
                 all         120          60       0.652       0.533       0.586       0.268
val_obj_loss=0.011756744235754013
patience_counter=2
      5/99     6.03G   0.02964  0.002667         0    0.0323        28       640:   7%|▋         | 1/15 [00:00<00:06,  2.24it/s]  2.92it/s]
      5/99     6.03G   0.03187  0.002922         0   0.03479        32       640:  13%|█▎        | 2/15 [00:50<06:26, 29.72s/it]  2.92it/s]
      5/99     6.03G   0.03126  0.003433         0   0.03469        27       640:  33%|███▎      | 5/15 [01:07<01:32,  9.26s/it]  2.92it/s]
      5/99     6.03G   0.03184  0.003581         0   0.03542        37       640:  40%|████      | 6/15 [01:45<02:51, 19.08s/it]  2.92it/s]
      5/99     6.03G   0.03191  0.003839         0   0.03575        27       640:  60%|██████    | 9/15 [02:08<00:58,  9.68s/it]  2.92it/s]
      5/99     6.03G   0.03184  0.003763         0    0.0356        34       640:  67%|██████▋   | 10/15 [02:40<01:22, 16.44s/it] 2.92it/s]
      5/99     6.03G   0.03201  0.003515         0   0.03553        24       640:  87%|████████▋ | 13/15 [03:03<00:18,  9.02s/it] 2.92it/s]
      5/99     6.03G   0.03243  0.003542         0   0.03597        32       640:  93%|█████████▎| 14/15 [03:34<00:15, 15.78s/it] 2.92it/s]
      5/99     6.03G   0.03229  0.003591         0   0.03588        35       640: 100%|██████████| 15/15 [04:02<00:00, 16.18s/it] 2.92it/s]
      5/99     6.03G   0.03229  0.003591         0   0.03588        35       640: 100%|██████████| 15/15 [04:02<00:00, 16.18s/it] 2.92it/s]
                 all         120          60       0.287       0.433       0.269       0.131
val_obj_loss=0.04494452476501465
patience_counter=3
Epoch 6/100 on device cuda:0
      6/99     6.03G    0.0305  0.003798         0    0.0343        26       640:  20%|██        | 3/15 [00:39<03:33, 17.78s/it]] 2.92it/s]
      6/99     6.03G   0.03083  0.003783         0   0.03461        33       640:  40%|████      | 6/15 [01:02<01:17,  8.58s/it]] 2.92it/s]
      6/99     6.03G   0.03038  0.003828         0   0.03421        40       640:  47%|████▋     | 7/15 [01:38<02:18, 17.26s/it]] 2.92it/s]
      6/99     6.03G   0.03089  0.003833         0   0.03472        36       640:  67%|██████▋   | 10/15 [02:01<00:46,  9.20s/it] 2.92it/s]
      6/99     6.03G   0.03083  0.003678         0   0.03451        16       640:  73%|███████▎  | 11/15 [02:29<01:00, 15.06s/it] 2.92it/s]
      6/99     6.03G   0.03027   0.00354         0   0.03381        38       640:  93%|█████████▎| 14/15 [03:04<00:10, 10.38s/it] 2.92it/s]
      6/99     6.03G   0.03014   0.00357         0   0.03371        30       640: 100%|██████████| 15/15 [03:21<00:00, 13.45s/it] 2.92it/s]
      6/99     6.03G   0.03014   0.00357         0   0.03371        30       640: 100%|██████████| 15/15 [03:21<00:00, 13.45s/it] 2.92it/s]
  0%|          | 0/15 [00:00<?, ?it/s]Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
  0%|          | 0/15 [00:00<?, ?it/s]Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
val_obj_loss=0.009027194231748581
patience_counter=4
      7/99     6.03G   0.03586  0.003638         0    0.0395        40       640:  20%|██        | 3/15 [00:48<02:11, 10.93s/it]  3.13it/s]
      7/99     6.03G   0.03648  0.003437         0   0.03991        21       640:  27%|██▋       | 4/15 [01:10<02:47, 15.22s/it]  3.13it/s]
      7/99     6.03G   0.03594  0.003665         0   0.03961        36       640:  40%|████      | 6/15 [01:46<02:16, 15.22s/it]  3.13it/s]
      7/99     6.03G   0.03501   0.00365         0   0.03866        31       640:  47%|████▋     | 7/15 [01:47<01:22, 10.36s/it]  3.13it/s]
      7/99     6.03G   0.03531  0.003543         0   0.03886        31       640:  53%|█████▎    | 8/15 [02:04<01:27, 12.50s/it]  3.13it/s]
      7/99     6.03G   0.03441   0.00338         0   0.03779        19       640:  73%|███████▎  | 11/15 [02:46<00:41, 10.45s/it] 3.13it/s]
      7/99     6.03G   0.03431  0.003334         0   0.03764        25       640:  80%|████████  | 12/15 [03:08<00:42, 14.18s/it] 3.13it/s]
      7/99     6.03G   0.03429  0.003549         0   0.03784        35       640: 100%|██████████| 15/15 [03:48<00:00, 15.25s/it] 3.13it/s]
      7/99     6.03G   0.03429  0.003549         0   0.03784        35       640: 100%|██████████| 15/15 [03:48<00:00, 15.25s/it] 3.13it/s]
               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
val_obj_loss=0.10962381958961487
patience_counter=5
Early stopping at epoch 8 due to no improvement in validation object loss.
8 epochs completed in 0.525 hours.    Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
8 epochs completed in 0.525 hours.    Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
Optimizer stripped from runs/train/experiments/SIGGI_5_adam/weights/best.pt, 12.3MB